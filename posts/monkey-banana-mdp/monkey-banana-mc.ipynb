{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Solving the monkey banana problem with monte carlo methods\n",
    "author: Kim Young Jin\n",
    "date: '2024-05-28'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Monte Carlo, unlike in Dynamic Programming, we remove absolute knowledge of the environment so that the agent will learn from its own experience by undergoing repeated episodes. We use the algorithm outlined below from Sutton & Barto's \"Reinforcement Learning: An Introduction\".\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "![Algorithm](on-policy-first-visit-algo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video contains a few runs of the agent completing the task. Since the policy is stochastic, we can see the agent sometimes making some non-optimal moves.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{{< video mc.mov >}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
