{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Solving the monkey banana problem with dynamic programming\n",
    "author: Kim Young Jin\n",
    "date: '2024-05-25'\n",
    "categories: [\"code\"]\n",
    "subtitle: Dynamic programming code for the Monkey Banana problem\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a simplified Monkey Banana environment to test classical RL methods on.\n",
    "\n",
    "The environment is a \"2D world\" with discrete and finite states, actions, and rewards. It is fully observable to our agent, the Monkey.\n",
    "\n",
    "### State\n",
    "\n",
    "State consists of 5 values:\n",
    "\n",
    "- agent position (x-axis)\n",
    "- chair position (x-axis)\n",
    "- banana position (x-axis)\n",
    "- is_holding_chair (0 or 1)\n",
    "- on_chair (0 or 1)\n",
    "\n",
    "We do not explicitly model the y-axis, since all we care about is whether the Monkey is on the chair when he reaches for the banana.\n",
    "\n",
    "### Actions\n",
    "\n",
    "- move left one step\n",
    "- move right one step\n",
    "- climb on the chair\n",
    "- climb down the chair\n",
    "- grab the chair\n",
    "- drop the chair\n",
    "- grab the banana\n",
    "\n",
    "### Rewards\n",
    "\n",
    "- -1 for each action\n",
    "- +10 for grabbing the banana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import os  # noqa\n",
    "import sys  # noqa\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"posts/monkey-banana-mdp/code\"))\n",
    "sys.path.insert(0, module_path)\n",
    "from environment import LineWorldEnv  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # noqa\n",
    "import pygame  # noqa\n",
    "\n",
    "import gymnasium as gym  # noqa\n",
    "from gymnasium import spaces  # noqa\n",
    "from gymnasium.envs.registration import register  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we test the setup by observing the Monkey take random actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = LineWorldEnv(render_mode=\"human\", size=5)\n",
    "obs, info = env.reset()\n",
    "\n",
    "for _ in range(50):\n",
    "    actions = env.get_possible_actions(env.flatten_obs(obs))\n",
    "    # Choose random action\n",
    "    action = np.random.choice(actions)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue circle is the Monkey, the green square is the chair, and the yellow square is the banana. On the top left you will see the action that is being taken.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{{< video random.mov >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use Dynamic Programming with value iteration to find the optimal policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = LineWorldEnv(size=10)\n",
    "obs, info = env.reset()\n",
    "\n",
    "all_states = env.get_all_states()\n",
    "state_values = {s: 0 for s in all_states}\n",
    "\n",
    "def action_evaluation(state, action):\n",
    "    env.set_obs(state)\n",
    "    next_state, reward, terminated, truncated, _  =  env.step(action)\n",
    "    flattened_next_state = env.flatten_obs(next_state)\n",
    "    value = reward + state_values[flattened_next_state]\n",
    "    return 0 if terminated else value\n",
    "\n",
    "# Value iteration\n",
    "theta = 0.1\n",
    "sweep_count = 0\n",
    "biggest_change = np.inf\n",
    "while biggest_change > theta:\n",
    "    biggest_change = 0\n",
    "    for s in all_states:\n",
    "        original_value = state_values[s]\n",
    "        best_value = -np.inf\n",
    "        possible_actions = env.get_possible_actions(s)\n",
    "        for action in possible_actions:\n",
    "            value = action_evaluation(s, action)\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "        state_values[s] = best_value\n",
    "        biggest_change = max(biggest_change, abs(original_value - state_values[s]))\n",
    "    sweep_count += 1\n",
    "print(\"Number of sweeps: \", sweep_count)\n",
    "env.close()\n",
    "\n",
    "# Create optimal policy pi from state values:\n",
    "policy = {} \n",
    "for s in all_states:\n",
    "      possible_actions = env.get_possible_actions(s)\n",
    "      best_value = -np.inf\n",
    "      best_action = None\n",
    "      for a in possible_actions:\n",
    "          value = action_evaluation(s, a)\n",
    "          if value > best_value:\n",
    "              best_value = value\n",
    "              best_action = a\n",
    "      policy[s] = best_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the Monkey following the optimal policy produced from Dynamic Programming:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = LineWorldEnv(render_mode=\"human\", size=10)\n",
    "cbs, info = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = policy[env.flatten_obs(obs)]\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        env.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{{< video dp.mov >}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
