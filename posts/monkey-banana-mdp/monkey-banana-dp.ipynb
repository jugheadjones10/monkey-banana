{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Solving the monkey banana problem with dynamic programming\n",
    "author: Kim Young Jin\n",
    "date: '2024-05-25'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a simplified Monkey Banana environment to test classical RL methods on.\n",
    "\n",
    "The environment is a \"2D world\" with discrete and finite states, actions, and rewards. It is fully observable to our agent, the Monkey.\n",
    "\n",
    "### State\n",
    "\n",
    "State consists of 5 values:\n",
    "\n",
    "- agent position (x-axis)\n",
    "- chair position (x-axis)\n",
    "- banana position (x-axis)\n",
    "- is_holding_chair (0 or 1)\n",
    "- on_chair (0 or 1)\n",
    "\n",
    "As you can see, we do not explicitly model the y-axis, since all we care about is whether the Monkey is on the chair when he reaches for the banana.\n",
    "\n",
    "### Actions\n",
    "\n",
    "- move left one step\n",
    "- move right one step\n",
    "- climb on the chair\n",
    "- climb down the chair\n",
    "- grab the chair\n",
    "- drop the chair\n",
    "- grab the banana\n",
    "\n",
    "### Rewards\n",
    "\n",
    "- -1 for each action\n",
    "- +10 for grabbing the banana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we test the setup by observing the Monkey take random actions.\n",
    "\n",
    "The blue circle is the Monkey, the green square is the chair, and the yellow square is the banana. On the top left you will see the action that is being taken by the Monkey.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{{< video random.mov >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use Dynamic Programming with value iteration to find the optimal policy. After around 17 iterations, the policy converges to the optimal policy, shown below in action.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{{< video dp.mov >}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
